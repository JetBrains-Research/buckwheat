{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import pygments\n",
    "from pygments.lexers.javascript import JavascriptLexer, TypeScriptLexer\n",
    "from pygments.lexers.python import PythonLexer\n",
    "from pygments.lexers.jvm import JavaLexer, ScalaLexer, KotlinLexer\n",
    "from pygments.lexers.go import GoLexer\n",
    "from pygments.lexers.c_cpp import CppLexer, CLexer\n",
    "from pygments.lexers.ruby import RubyLexer\n",
    "from pygments.lexers.php import PhpLexer\n",
    "from pygments.lexers.dotnet import CSharpLexer\n",
    "from pygments.lexers.shell import BashLexer\n",
    "from pygments.lexers.rust import RustLexer\n",
    "from pygments.lexers.objective import SwiftLexer\n",
    "from pygments.lexers.haskell import HaskellLexer\n",
    "from tree_sitter import Language, Parser\n",
    "import tree_sitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree_sitter_dir() -> str:\n",
    "    \"\"\"\n",
    "    Get tree-sitter directory.\n",
    "    :return: absolute path.\n",
    "    \"\"\"\n",
    "    return os.path.abspath('../parsers/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree_sitter_so() -> str:\n",
    "    \"\"\"\n",
    "    Get build tree-sitter `.so` location.\n",
    "    :return: absolute path.\n",
    "    \"\"\"\n",
    "    tree_sitter_dir = get_tree_sitter_dir()\n",
    "    bin_loc = os.path.join(tree_sitter_dir, \"build/langs.so\")\n",
    "    return bin_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    Initialize tree-sitter library.\n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    # root directory for tree-sitter\n",
    "    tree_sitter_dir = get_tree_sitter_dir()\n",
    "    # grammar locations\n",
    "    cpp_grammar_loc = os.path.join(tree_sitter_dir, \"vendor/tree-sitter-cpp\")\n",
    "    java_grammar_loc = os.path.join(tree_sitter_dir, \"vendor/tree-sitter-java\")\n",
    "    python_grammar_loc = os.path.join(tree_sitter_dir, \"vendor/tree-sitter-python\")\n",
    "    javascript_grammar_loc = os.path.join(tree_sitter_dir, \"vendor/tree-sitter-javascript\")\n",
    "    go_grammar_loc = os.path.join(tree_sitter_dir, \"vendor/tree-sitter-go\")\n",
    "    ruby_grammar_loc = os.path.join(tree_sitter_dir, \"vendor/tree-sitter-ruby\")\n",
    "    typescript_grammar_loc = os.path.join(tree_sitter_dir, \"vendor/tree-sitter-typescript/typescript\")\n",
    "    php_grammar_loc = os.path.join(tree_sitter_dir, \"vendor/tree-sitter-php\")\n",
    "    c_sharp_grammar_loc = os.path.join(tree_sitter_dir, \"vendor/tree-sitter-c-sharp\")\n",
    "    c_grammar_loc = os.path.join(tree_sitter_dir, \"vendor/tree-sitter-c\")\n",
    "    bash_sharp_grammar_loc = os.path.join(tree_sitter_dir, \"vendor/tree-sitter-bash\")\n",
    "    rust_grammar_loc = os.path.join(tree_sitter_dir, \"vendor/tree-sitter-rust\")\n",
    "    swift_grammar_loc = os.path.join(tree_sitter_dir, \"vendor/tree-sitter-swift\")\n",
    "    # location for library\n",
    "    bin_loc = get_tree_sitter_so()\n",
    "    # build everything\n",
    "    Language.build_library(\n",
    "        # Store the library in the `bin_loc`\n",
    "        bin_loc,\n",
    "        # Include languages\n",
    "        [\n",
    "            go_grammar_loc,\n",
    "            cpp_grammar_loc,\n",
    "            java_grammar_loc,\n",
    "            python_grammar_loc,\n",
    "            javascript_grammar_loc,\n",
    "            ruby_grammar_loc,\n",
    "            typescript_grammar_loc,\n",
    "            php_grammar_loc,\n",
    "            c_sharp_grammar_loc,\n",
    "            c_grammar_loc,\n",
    "            bash_sharp_grammar_loc,\n",
    "            rust_grammar_loc,\n",
    "            swift_grammar_loc\n",
    "        ]\n",
    "    )\n",
    "    print(\"Parser successfully initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parser successfully initialized.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARSERS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parser(lang: str) -> Parser:\n",
    "    \"\"\"\n",
    "    Initialize parser for a specific language.\n",
    "    :param lang: language to use.\n",
    "    :return: parser.\n",
    "    \"\"\"\n",
    "    global PARSERS\n",
    "    if lang not in PARSERS:\n",
    "        parser = Parser()\n",
    "        parser.set_language(Language(get_tree_sitter_so(), lang))\n",
    "        PARSERS[lang] = parser\n",
    "    else:\n",
    "        parser = PARSERS[lang]\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_bytes(node: tree_sitter.Node) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Extract start and end byte of the tree-sitter Node.\n",
    "    :param node: node on the AST.\n",
    "    :return: (start byte, end byte).\n",
    "    \"\"\"\n",
    "    start = node.start_byte\n",
    "    end = node.end_byte\n",
    "    return start, end\n",
    "\n",
    "def get_tokens(content: str, lang: str) -> Tuple[Counter, set]:\n",
    "    \"\"\"\n",
    "    Gather a Counter object of tokens in the file and their count, as well as a set of all\n",
    "    encountered tokens.\n",
    "    :param file: the path to the file.\n",
    "    :param lang: the language of file.\n",
    "    :return: a Counter object of items: token and count, and a set of all tokens.\n",
    "    \"\"\"\n",
    "    content = bytes(content, \"utf-8\")\n",
    "    tree = get_parser(lang).parse(content)\n",
    "    root = tree.root_node\n",
    "    tokens = []\n",
    "\n",
    "    def traverse_tree(node: tree_sitter.Node) -> None:\n",
    "        \"\"\"\n",
    "        Run down the AST (DFS) from a given node and gather tokens from its children.\n",
    "        :param node: starting node.\n",
    "        :return: None.\n",
    "        \"\"\"\n",
    "        for child in node.children:\n",
    "            start, end = get_positional_bytes(child)\n",
    "            token = content[start:end].decode(\"utf-8\")\n",
    "            tokens.append([child.type, token])\n",
    "            if len(child.children) != 0:\n",
    "                try:\n",
    "                    traverse_tree(child)\n",
    "                except RecursionError:\n",
    "                    continue\n",
    "\n",
    "    traverse_tree(root)\n",
    "    types = set()\n",
    "    identifiers = []\n",
    "    for token in tokens:\n",
    "        if ((\"identifier\" in token[0])) and (\"scoped\" not in token[0]) and (\"nested\" not in token[0]):\n",
    "            types.add(token[0])\n",
    "            identifiers.append(token[1])\n",
    "    print(types)\n",
    "    print(identifiers)\n",
    "\n",
    "    #for token in tokens:\n",
    "    #    if \"identifier\" in token[0]:\n",
    "    #        print(\">>> \", token[0], \"\\n\\n\", token[1], \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_pygments(content: str, lang: str) -> Tuple[Counter, set]:\n",
    "    \"\"\"\n",
    "    Gather a Counter object of tokens in the file and their count, as well as a set of all\n",
    "    encountered tokens.\n",
    "    :param file: the path to the file.\n",
    "    :param lang: the language of file.\n",
    "    :return: a Counter object of items: token and count, and a set of all tokens.\n",
    "    \"\"\"\n",
    "    LEXERS = {\"javascript\": JavascriptLexer(),\n",
    "              \"python\": PythonLexer(),\n",
    "              \"java\": JavaLexer(),\n",
    "              \"go\": GoLexer(),\n",
    "              \"cpp\": CppLexer(),\n",
    "              \"ruby\": RubyLexer(),\n",
    "              \"typescript\": TypeScriptLexer(),\n",
    "              \"php\": PhpLexer(),\n",
    "              \"c-sharp\": CSharpLexer(),\n",
    "              \"c\": CLexer(),\n",
    "              \"scala\": ScalaLexer(),\n",
    "              \"bash\": BashLexer(),\n",
    "              \"rust\": RustLexer(),\n",
    "              \"swift\": SwiftLexer(),\n",
    "              \"kotlin\": KotlinLexer(),\n",
    "              \"haskell\": HaskellLexer()}\n",
    "    identifiers = []\n",
    "    types = set()\n",
    "    for pair in pygments.lex(content, LEXERS[lang]):\n",
    "        if any(pair[0] in sublist for sublist in [pygments.token.Name, pygments.token.Comment.PreprocFile]):\n",
    "            types.add(pair[0])\n",
    "            identifiers.append(pair[1])\n",
    "    print(types)\n",
    "    print(identifiers)\n",
    "    #for pair in pygments.lex(content, LEXERS[lang]):\n",
    "    #    if any(pair[0] in sublist for sublist in [pygments.token.Name, pygments.token.Comment.PreprocFile]):\n",
    "    #    print('(', pair[0], ')', pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "'use strict';\n",
    "\n",
    "const path = require('path');\n",
    "const { Metadata } = require('../../packages/icon-build-helpers');\n",
    "\n",
    "const ICONS_PACKAGE_DIR = path.resolve(__dirname, '../../packages/icons');\n",
    "const sizes = [16, 20, 24, 32];\n",
    "\n",
    "describe('@carbon/icons', () => {\n",
    "  let metadata;\n",
    "\n",
    "  beforeAll(async () => {\n",
    "    metadata = await Metadata.load({\n",
    "      input: ICONS_PACKAGE_DIR,\n",
    "      extensions: [\n",
    "        Metadata.extensions.icons,\n",
    "        Metadata.extensions.deprecated,\n",
    "        Metadata.extensions.moduleName,\n",
    "      ],\n",
    "    });\n",
    "  });\n",
    "\n",
    "  it('should export each SVG asset', async () => {\n",
    "    const CarbonIconsCommonJS = require('@carbon/icons');\n",
    "    const CarbonIconsESM = await import('@carbon/icons');\n",
    "\n",
    "    for (const icon of metadata.icons) {\n",
    "      const { moduleName } = icon;\n",
    "      for (const size of sizes) {\n",
    "        const exportName = `${moduleName}${size}`;\n",
    "        expect(CarbonIconsCommonJS[exportName]).toBeDefined();\n",
    "        expect(CarbonIconsESM[exportName]).toBeDefined();\n",
    "      }\n",
    "    }\n",
    "  });\n",
    "\n",
    "  it('should export each SVG asset as a direct path', async () => {\n",
    "    for (const icon of metadata.icons) {\n",
    "      const esm = path.join(\n",
    "        ICONS_PACKAGE_DIR,\n",
    "        'es',\n",
    "        ...icon.namespace,\n",
    "        icon.name\n",
    "      );\n",
    "      const commonjs = path.join(\n",
    "        ICONS_PACKAGE_DIR,\n",
    "        'lib',\n",
    "        ...icon.namespace,\n",
    "        icon.name\n",
    "      );\n",
    "\n",
    "      for (const size of sizes) {\n",
    "        const es = path.join(esm, `${size}.js`);\n",
    "        const lib = path.join(commonjs, `${size}.js`);\n",
    "        expect(() => {\n",
    "          require(lib);\n",
    "        }).not.toThrow();\n",
    "        await expect(import(es)).resolves.toBeDefined();\n",
    "      }\n",
    "    }\n",
    "  });\n",
    "});\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'property_identifier', 'shorthand_property_identifier', 'identifier'}\n",
      "['path', 'require', 'Metadata', 'require', 'ICONS_PACKAGE_DIR', 'path', 'resolve', '__dirname', 'sizes', 'describe', 'metadata', 'beforeAll', 'metadata', 'Metadata', 'load', 'input', 'ICONS_PACKAGE_DIR', 'extensions', 'Metadata', 'extensions', 'icons', 'Metadata', 'extensions', 'deprecated', 'Metadata', 'extensions', 'moduleName', 'it', 'CarbonIconsCommonJS', 'require', 'CarbonIconsESM', 'icon', 'metadata', 'icons', 'moduleName', 'icon', 'size', 'sizes', 'exportName', 'moduleName', 'size', 'expect', 'CarbonIconsCommonJS', 'exportName', 'toBeDefined', 'expect', 'CarbonIconsESM', 'exportName', 'toBeDefined', 'it', 'icon', 'metadata', 'icons', 'esm', 'path', 'join', 'ICONS_PACKAGE_DIR', 'icon', 'namespace', 'icon', 'name', 'commonjs', 'path', 'join', 'ICONS_PACKAGE_DIR', 'icon', 'namespace', 'icon', 'name', 'size', 'sizes', 'es', 'path', 'join', 'esm', 'size', 'lib', 'path', 'join', 'commonjs', 'size', 'expect', 'require', 'lib', 'not', 'toThrow', 'expect', 'es', 'resolves', 'toBeDefined']\n"
     ]
    }
   ],
   "source": [
    "get_tokens(content, \"javascript\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Token.Name.Other}\n",
      "['path', 'require', 'Metadata', 'require', 'ICONS_PACKAGE_DIR', 'path', 'resolve', '__dirname', 'sizes', 'describe', 'metadata', 'beforeAll', 'async', 'metadata', 'await', 'Metadata', 'load', 'input', 'ICONS_PACKAGE_DIR', 'extensions', 'Metadata', 'extensions', 'icons', 'Metadata', 'extensions', 'deprecated', 'Metadata', 'extensions', 'moduleName', 'it', 'async', 'CarbonIconsCommonJS', 'require', 'CarbonIconsESM', 'await', 'icon', 'metadata', 'icons', 'moduleName', 'icon', 'size', 'sizes', 'exportName', 'moduleName', 'size', 'expect', 'CarbonIconsCommonJS', 'exportName', 'toBeDefined', 'expect', 'CarbonIconsESM', 'exportName', 'toBeDefined', 'it', 'async', 'icon', 'metadata', 'icons', 'esm', 'path', 'join', 'ICONS_PACKAGE_DIR', 'icon', 'namespace', 'icon', 'name', 'commonjs', 'path', 'join', 'ICONS_PACKAGE_DIR', 'icon', 'namespace', 'icon', 'name', 'size', 'sizes', 'es', 'path', 'join', 'esm', 'size', 'lib', 'path', 'join', 'commonjs', 'size', 'expect', 'require', 'lib', 'not', 'toThrow', 'await', 'expect', 'es', 'resolves', 'toBeDefined']\n"
     ]
    }
   ],
   "source": [
    "get_tokens_pygments(content, \"javascript\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "def clone_repository(repository: str, directory: str) -> None:\n",
    "    repository = repository[:8] + \"user:password@\" + repository[8:]\n",
    "    os.system(\"git clone --quiet --depth 1 {repository} {directory}\".format(repository=repository,\n",
    "                                                                            directory=directory))\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'identifier'}\n",
      "['clone_repository', 'repository', 'str', 'directory', 'str', 'repository', 'repository', 'repository', 'os', 'system', 'format', 'repository', 'repository', 'directory', 'directory']\n"
     ]
    }
   ],
   "source": [
    "get_tokens(content, \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Token.Name.Builtin, Token.Name.Function, Token.Name}\n",
      "['clone_repository', 'repository', 'str', 'directory', 'str', 'repository', 'repository', 'repository', 'os', 'system', 'format', 'repository', 'repository', 'directory', 'directory']\n"
     ]
    }
   ],
   "source": [
    "get_tokens_pygments(content, \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "package com.company.project;\n",
    "\n",
    "import org.springframework.boot.SpringApplication;\n",
    "import org.springframework.boot.autoconfigure.SpringBootApplication;\n",
    "\n",
    "@SpringBootApplication\n",
    "public class Application {\n",
    "    public static void main(String[] args) {\n",
    "        SpringApplication.run(Application.class, args);\n",
    "    }\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scoped_identifier', 'type_identifier', 'identifier'}\n",
      "['com.company.project', 'com.company', 'com', 'company', 'project', 'org', 'springframework', 'boot', 'SpringApplication', 'org', 'springframework', 'boot', 'autoconfigure', 'SpringBootApplication', 'SpringBootApplication', 'Application', 'main', 'String', 'args', 'SpringApplication', 'run', 'Application', 'args']\n"
     ]
    }
   ],
   "source": [
    "get_tokens(content, \"java\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Token.Name.Attribute, Token.Name.Namespace, Token.Name, Token.Name.Function, Token.Name.Class, Token.Name.Decorator}\n",
      "['com.company.project', 'org.springframework.boot.SpringApplication', 'org.springframework.boot.autoconfigure.SpringBootApplication', '@SpringBootApplication', 'Application', 'main', 'String', 'args', 'SpringApplication', 'run', 'Application', 'class', 'args']\n"
     ]
    }
   ],
   "source": [
    "get_tokens_pygments(content, \"java\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "func makeRequestLoop(url string, jsonBytes []byte) {\n",
    "\tvar i int\n",
    "\tfor true {\n",
    "\t\tif _numRequestsPerThread > 0 {\n",
    "\t\t\tif i >= _numRequestsPerThread {\n",
    "\t\t\t\treturn\n",
    "\t\t\t}\n",
    "\t\t\ti++\n",
    "\t\t}\n",
    "\n",
    "\t\tresponse, _, err := makeRequest(url, jsonBytes)\n",
    "\n",
    "\t\tif err != nil {\n",
    "\t\t\tfmt.Print(err.Error())\n",
    "\t\t\tcontinue\n",
    "\t\t}\n",
    "\n",
    "\t\tif response.StatusCode != 200 {\n",
    "\t\t\tfmt.Print(response.StatusCode)\n",
    "\t\t\tfmt.Print(\" \")\n",
    "\t\t\tcontinue\n",
    "\t\t}\n",
    "\n",
    "\t\t// fmt.Print(\".\")\n",
    "\n",
    "\t\tif _requestDelay != 0 {\n",
    "\t\t\ttime.Sleep(_requestDelay)\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type_identifier', 'identifier', 'field_identifier'}\n",
      "['makeRequestLoop', 'url', 'string', 'jsonBytes', 'byte', 'i', 'int', '_numRequestsPerThread', 'i', '_numRequestsPerThread', 'i', 'response', '_', 'err', 'makeRequest', 'url', 'jsonBytes', 'err', 'fmt', 'Print', 'err', 'Error', 'response', 'StatusCode', 'fmt', 'Print', 'response', 'StatusCode', 'fmt', 'Print', '_requestDelay', 'time', 'Sleep', '_requestDelay']\n"
     ]
    }
   ],
   "source": [
    "get_tokens(content, 'go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Token.Name.Other}\n",
      "['makeRequestLoop', 'url', 'jsonBytes', 'i', '_numRequestsPerThread', 'i', '_numRequestsPerThread', 'i', 'response', '_', 'err', 'makeRequest', 'url', 'jsonBytes', 'err', 'fmt', 'Print', 'err', 'Error', 'response', 'StatusCode', 'fmt', 'Print', 'response', 'StatusCode', 'fmt', 'Print', '_requestDelay', 'time', 'Sleep', '_requestDelay']\n"
     ]
    }
   ],
   "source": [
    "get_tokens_pygments(content, \"go\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "int x = (a) * (b);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'identifier'}\n",
      "['x', 'a', 'b']\n"
     ]
    }
   ],
   "source": [
    "get_tokens(content, \"cpp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Token.Name.Function, Token.Name}\n",
      "['main', 'x', 'string', 'c', 'foo', 'x']\n"
     ]
    }
   ],
   "source": [
    "get_tokens_pygments(content, \"cpp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "# frozen_string_literal: true\n",
    "\n",
    "module BbbApi\n",
    "  RETURNCODE_SUCCESS = \"SUCCESS\"\n",
    "\n",
    "  def bbb_endpoint\n",
    "    Rails.configuration.bigbluebutton_endpoint\n",
    "  end\n",
    "\n",
    "  def bbb_secret\n",
    "    Rails.configuration.bigbluebutton_secret\n",
    "  end\n",
    "\n",
    "  # Sets a BigBlueButtonApi object for interacting with the API.\n",
    "  def bbb(user_provider)\n",
    "    if Rails.configuration.loadbalanced_configuration\n",
    "      user_domain = retrieve_provider_info(user_provider)\n",
    "\n",
    "      BigBlueButton::BigBlueButtonApi.new(remove_slash(user_domain[\"apiURL\"]), user_domain[\"secret\"], \"0.8\")\n",
    "    else\n",
    "      BigBlueButton::BigBlueButtonApi.new(remove_slash(bbb_endpoint), bbb_secret, \"0.8\")\n",
    "    end\n",
    "  end\n",
    "\n",
    "  # Rereives info from the loadbalanced in regards to a Provider (or tenant).\n",
    "  def retrieve_provider_info(provider, api = 'api', route = 'getUser')\n",
    "    # Include Omniauth accounts under the Greenlight provider.\n",
    "    raise \"Provider not included.\" if !provider || provider.empty?\n",
    "\n",
    "    cached_provider = Rails.cache.fetch(\"#{provider}/#{route}\")\n",
    "    # Return cached result if the value exists and cache is enabled\n",
    "    return cached_provider if !cached_provider.nil? && Rails.configuration.enable_cache\n",
    "\n",
    "    # Build the URI.\n",
    "    uri = encode_bbb_url(\n",
    "      Rails.configuration.loadbalancer_endpoint + api + '/',\n",
    "      Rails.configuration.loadbalancer_secret,\n",
    "      { name: provider },\n",
    "      route\n",
    "    )\n",
    "\n",
    "    logger.info uri\n",
    "\n",
    "    # Make the request.\n",
    "    http = Net::HTTP.new(uri.host, uri.port)\n",
    "    http.use_ssl = (uri.scheme == 'https')\n",
    "    response = http.get(uri.request_uri)\n",
    "\n",
    "    # Parse XML.\n",
    "    doc = XmlSimple.xml_in(response.body, 'ForceArray' => false)\n",
    "\n",
    "    raise doc['message'] unless response.is_a?(Net::HTTPSuccess)\n",
    "\n",
    "    # Return the user credentials if the request succeeded on the loadbalancer.\n",
    "    Rails.cache.fetch(\"#{provider}/#{route}\", expires_in: 1.hours) do\n",
    "      doc['user']\n",
    "    end\n",
    "\n",
    "    return doc['user'] if doc['returncode'] == 'SUCCESS'\n",
    "\n",
    "    raise \"User with provider #{provider} does not exist.\" if doc['messageKey'] == 'noSuchUser'\n",
    "    raise \"API call #{url} failed with #{doc['messageKey']}.\"\n",
    "  end\n",
    "\n",
    "  # Builds a request to retrieve credentials from the load balancer.\n",
    "  def encode_bbb_url(base_url, secret, params, route = 'getUser')\n",
    "    encoded_params = params.to_param\n",
    "    string = route + encoded_params + secret\n",
    "    checksum = OpenSSL::Digest.digest('sha1', string).unpack1('H*')\n",
    "\n",
    "    URI.parse(\"#{base_url}#{route}?#{encoded_params}&checksum=#{checksum}\")\n",
    "  end\n",
    "\n",
    "  # Removes trailing forward slash from a URL.\n",
    "  def remove_slash(s)\n",
    "    s.nil? ? nil : s.chomp(\"/\")\n",
    "  end\n",
    "end\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'symbol', 'identifier', 'constant'}\n",
      "['BbbApi', 'RETURNCODE_SUCCESS', 'bbb_endpoint', 'Rails', 'configuration', 'bigbluebutton_endpoint', 'bbb_secret', 'Rails', 'configuration', 'bigbluebutton_secret', 'bbb', 'user_provider', 'Rails', 'configuration', 'loadbalanced_configuration', 'user_domain', 'retrieve_provider_info', 'user_provider', 'BigBlueButton', 'BigBlueButtonApi', 'new', 'remove_slash', 'user_domain', 'user_domain', 'BigBlueButton', 'BigBlueButtonApi', 'new', 'remove_slash', 'bbb_endpoint', 'bbb_secret', 'retrieve_provider_info', 'provider', 'api', 'route', 'raise', 'provider', 'provider', 'empty?', 'cached_provider', 'Rails', 'cache', 'fetch', 'provider', 'route', 'cached_provider', 'cached_provider', 'nil?', 'Rails', 'configuration', 'enable_cache', 'uri', 'encode_bbb_url', 'Rails', 'configuration', 'loadbalancer_endpoint', 'api', 'Rails', 'configuration', 'loadbalancer_secret', 'name', 'provider', 'route', 'logger', 'info', 'uri', 'http', 'Net', 'HTTP', 'new', 'uri', 'host', 'uri', 'port', 'http', 'use_ssl', 'uri', 'scheme', 'response', 'http', 'get', 'uri', 'request_uri', 'doc', 'XmlSimple', 'xml_in', 'response', 'body', 'raise', 'doc', 'response', 'is_a?', 'Net', 'HTTPSuccess', 'Rails', 'cache', 'fetch', 'provider', 'route', 'expires_in', 'hours', 'doc', 'doc', 'doc', 'raise', 'provider', 'doc', 'raise', 'url', 'doc', 'encode_bbb_url', 'base_url', 'secret', 'params', 'route', 'encoded_params', 'params', 'to_param', 'string', 'route', 'encoded_params', 'secret', 'checksum', 'OpenSSL', 'Digest', 'digest', 'string', 'unpack1', 'URI', 'parse', 'base_url', 'route', 'encoded_params', 'checksum', 'remove_slash', 's', 's', 'nil?', 's', 'chomp']\n"
     ]
    }
   ],
   "source": [
    "get_tokens(content, \"ruby\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Token.Name.Namespace, Token.Name, Token.Name.Builtin, Token.Name.Function, Token.Name.Constant}\n",
      "['BbbApi', 'RETURNCODE_SUCCESS', 'bbb_endpoint', 'Rails', 'configuration', 'bigbluebutton_endpoint', 'bbb_secret', 'Rails', 'configuration', 'bigbluebutton_secret', 'bbb', 'user_provider', 'Rails', 'configuration', 'loadbalanced_configuration', 'user_domain', 'retrieve_provider_info', 'user_provider', 'BigBlueButton', 'BigBlueButtonApi', 'new', 'remove_slash', 'user_domain', 'user_domain', 'BigBlueButton', 'BigBlueButtonApi', 'new', 'remove_slash', 'bbb_endpoint', 'bbb_secret', 'retrieve_provider_info', 'provider', 'api', 'route', 'provider', 'provider', 'empty?', 'cached_provider', 'Rails', 'cache', 'fetch', 'provider', 'route', 'cached_provider', 'cached_provider', 'nil?', 'Rails', 'configuration', 'enable_cache', 'uri', 'encode_bbb_url', 'Rails', 'configuration', 'loadbalancer_endpoint', 'api', 'Rails', 'configuration', 'loadbalancer_secret', 'name', 'provider', 'route', 'logger', 'info', 'uri', 'http', 'Net', 'HTTP', 'new', 'uri', 'host', 'uri', 'port', 'http', 'use_ssl', 'uri', 'scheme', 'response', 'http', 'get', 'uri', 'request_uri', 'doc', 'XmlSimple', 'xml_in', 'response', 'body', 'doc', 'response', 'is_a?', 'Net', 'HTTPSuccess', 'Rails', 'cache', 'fetch', 'provider', 'route', 'hours', 'doc', 'doc', 'doc', 'provider', 'doc', 'url', 'doc', 'encode_bbb_url', 'base_url', 'secret', 'params', 'route', 'encoded_params', 'params', 'to_param', 'string', 'route', 'encoded_params', 'secret', 'checksum', 'OpenSSL', 'Digest', 'digest', 'string', 'unpack1', 'URI', 'parse', 'base_url', 'route', 'encoded_params', 'checksum', 'remove_slash', 's', 's', 'nil?', 's', 'chomp']\n"
     ]
    }
   ],
   "source": [
    "get_tokens_pygments(content, \"ruby\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "@NgModule({\n",
    "  declarations: DECLARATIONS,\n",
    "  exports: DECLARATIONS,\n",
    "  providers: [AngularDelegate, ModalController, PopoverController],\n",
    "  imports: [CommonModule]\n",
    "})\n",
    "export class IonicModule {\n",
    "  static forRoot(config?: IonicConfig): ModuleWithProviders<IonicModule> {\n",
    "    return {\n",
    "      ngModule: IonicModule,\n",
    "      providers: [\n",
    "        {\n",
    "          provide: ConfigToken,\n",
    "          useValue: config\n",
    "        },\n",
    "        {\n",
    "          provide: APP_INITIALIZER,\n",
    "          useFactory: appInitialize,\n",
    "          multi: true,\n",
    "          deps: [\n",
    "            ConfigToken,\n",
    "            DOCUMENT,\n",
    "            NgZone\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    };\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'identifier', 'type_identifier', 'property_identifier'}\n",
      "['NgModule', 'declarations', 'DECLARATIONS', 'exports', 'DECLARATIONS', 'providers', 'AngularDelegate', 'ModalController', 'PopoverController', 'imports', 'CommonModule', 'IonicModule', 'forRoot', 'config', 'IonicConfig', 'ModuleWithProviders', 'IonicModule', 'ngModule', 'IonicModule', 'providers', 'provide', 'ConfigToken', 'useValue', 'config', 'provide', 'APP_INITIALIZER', 'useFactory', 'appInitialize', 'multi', 'deps', 'ConfigToken', 'DOCUMENT', 'NgZone']\n"
     ]
    }
   ],
   "source": [
    "get_tokens(content, \"typescript\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'identifier', 'type_identifier', 'property_identifier'}\n",
      "['NgModule', 'declarations', 'DECLARATIONS', 'exports', 'DECLARATIONS', 'providers', 'AngularDelegate', 'ModalController', 'PopoverController', 'imports', 'CommonModule', 'IonicModule', 'forRoot', 'config', 'IonicConfig', 'ModuleWithProviders', 'IonicModule', 'ngModule', 'IonicModule', 'providers', 'provide', 'ConfigToken', 'useValue', 'config', 'provide', 'APP_INITIALIZER', 'useFactory', 'appInitialize', 'multi', 'deps', 'ConfigToken', 'DOCUMENT', 'NgZone']\n"
     ]
    }
   ],
   "source": [
    "get_tokens(content, \"tsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Token.Name.Other}\n",
      "['declarations', 'exports', 'providers', 'AngularDelegate', 'ModalController', 'PopoverController', 'imports', 'CommonModule', 'IonicModule', 'forRoot', 'config?', 'ModuleWithProviders', 'IonicModule', 'ngModule', 'providers', 'provide', 'useValue', 'provide', 'useFactory', 'multi', 'deps', 'ConfigToken', 'DOCUMENT', 'NgZone']\n"
     ]
    }
   ],
   "source": [
    "get_tokens_pygments(content, \"typescript\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "<?php\n",
    "\n",
    "$factory->define(Form::class, function (Faker $faker) {\n",
    "    return [\n",
    "        'name'      => $faker->name,\n",
    "        'file_path' => $faker->url,\n",
    "        'school_id' => factory(School::class)->create()->id,\n",
    "        'user_id'   => function() use ($faker) {\n",
    "            if (User::count())\n",
    "                return $faker->randomElement(User::pluck('id')->toArray());\n",
    "            else return factory(User::class)->create()->id;\n",
    "        },\n",
    "    ];\n",
    "});\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name'}\n",
      "['factory', 'define', 'Form', 'class', 'Faker', 'faker', 'faker', 'name', 'faker', 'url', 'factory', 'School', 'class', 'create', 'id', 'faker', 'User', 'count', 'faker', 'randomElement', 'User', 'pluck', 'toArray', 'factory', 'User', 'class', 'create', 'id']\n"
     ]
    }
   ],
   "source": [
    "get_tokens(content, \"php\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Token.Name.Attribute, Token.Name.Other, Token.Name.Variable}\n",
      "['$factory', 'define', 'Form', 'class', 'Faker', '$faker', '$faker', 'name', '$faker', 'url', 'factory', 'School', 'class', 'create', 'id', '$faker', 'User', 'count', '$faker', 'randomElement', 'User', 'pluck', 'toArray', 'factory', 'User', 'class', 'create', 'id']\n"
     ]
    }
   ],
   "source": [
    "get_tokens_pygments(content, \"php\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "public async Task RenewJobRequestAsync(int poolId, long requestId, Guid lockToken, string orchestrationId, TaskCompletionSource<int> firstJobRequestRenewed, CancellationToken token)\n",
    "        {\n",
    "            var runnerServer = HostContext.GetService<IRunnerServer>();\n",
    "            TaskAgentJobRequest request = null;\n",
    "            int firstRenewRetryLimit = 5;\n",
    "            int encounteringError = 0;\n",
    "\n",
    "            // renew lock during job running.\n",
    "            // stop renew only if cancellation token for lock renew task been signal or exception still happen after retry.\n",
    "            while (!token.IsCancellationRequested)\n",
    "            {\n",
    "                try\n",
    "                {\n",
    "                    request = await runnerServer.RenewAgentRequestAsync(poolId, requestId, lockToken, orchestrationId, token);\n",
    "\n",
    "                    Trace.Info($\"Successfully renew job request {requestId}, job is valid till {request.LockedUntil.Value}\");\n",
    "\n",
    "                    if (!firstJobRequestRenewed.Task.IsCompleted)\n",
    "                    {\n",
    "                        // fire first renew succeed event.\n",
    "                        firstJobRequestRenewed.TrySetResult(0);\n",
    "                    }\n",
    "\n",
    "                    if (encounteringError > 0)\n",
    "                    {\n",
    "                        encounteringError = 0;\n",
    "                        runnerServer.SetConnectionTimeout(RunnerConnectionType.JobRequest, TimeSpan.FromSeconds(60));\n",
    "                        HostContext.WritePerfCounter(\"JobRenewRecovered\");\n",
    "                    }\n",
    "\n",
    "                    // renew again after 60 sec delay\n",
    "                    await HostContext.Delay(TimeSpan.FromSeconds(60), token);\n",
    "                }\n",
    "                catch (TaskAgentJobNotFoundException)\n",
    "                {\n",
    "                    // no need for retry. the job is not valid anymore.\n",
    "                    Trace.Info($\"TaskAgentJobNotFoundException received when renew job request {requestId}, job is no longer valid, stop renew job request.\");\n",
    "                    return;\n",
    "                }\n",
    "                catch (TaskAgentJobTokenExpiredException)\n",
    "                {\n",
    "                    // no need for retry. the job is not valid anymore.\n",
    "                    Trace.Info($\"TaskAgentJobTokenExpiredException received renew job request {requestId}, job is no longer valid, stop renew job request.\");\n",
    "                    return;\n",
    "                }\n",
    "                catch (OperationCanceledException) when (token.IsCancellationRequested)\n",
    "                {\n",
    "                    // OperationCanceledException may caused by http timeout or _lockRenewalTokenSource.Cance();\n",
    "                    // Stop renew only on cancellation token fired.\n",
    "                    Trace.Info($\"job renew has been canceled, stop renew job request {requestId}.\");\n",
    "                    return;\n",
    "                }\n",
    "                catch (Exception ex)\n",
    "                {\n",
    "                    Trace.Error($\"Catch exception during renew runner jobrequest {requestId}.\");\n",
    "                    Trace.Error(ex);\n",
    "                    encounteringError++;\n",
    "\n",
    "                    // retry\n",
    "                    TimeSpan remainingTime = TimeSpan.Zero;\n",
    "                    if (!firstJobRequestRenewed.Task.IsCompleted)\n",
    "                    {\n",
    "                        // retry 5 times every 10 sec for the first renew\n",
    "                        if (firstRenewRetryLimit-- > 0)\n",
    "                        {\n",
    "                            remainingTime = TimeSpan.FromSeconds(10);\n",
    "                        }\n",
    "                    }\n",
    "                    else\n",
    "                    {\n",
    "                        // retry till reach lockeduntil + 5 mins extra buffer.\n",
    "                        remainingTime = request.LockedUntil.Value + TimeSpan.FromMinutes(5) - DateTime.UtcNow;\n",
    "                    }\n",
    "\n",
    "                    if (remainingTime > TimeSpan.Zero)\n",
    "                    {\n",
    "                        TimeSpan delayTime;\n",
    "                        if (!firstJobRequestRenewed.Task.IsCompleted)\n",
    "                        {\n",
    "                            Trace.Info($\"Retrying lock renewal for jobrequest {requestId}. The first job renew request has failed.\");\n",
    "                            delayTime = BackoffTimerHelper.GetRandomBackoff(TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(10));\n",
    "                        }\n",
    "                        else\n",
    "                        {\n",
    "                            Trace.Info($\"Retrying lock renewal for jobrequest {requestId}. Job is valid until {request.LockedUntil.Value}.\");\n",
    "                            if (encounteringError > 5)\n",
    "                            {\n",
    "                                delayTime = BackoffTimerHelper.GetRandomBackoff(TimeSpan.FromSeconds(15), TimeSpan.FromSeconds(30));\n",
    "                            }\n",
    "                            else\n",
    "                            {\n",
    "                                delayTime = BackoffTimerHelper.GetRandomBackoff(TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(15));\n",
    "                            }\n",
    "                        }\n",
    "\n",
    "                        // Re-establish connection to server in order to avoid affinity with server.\n",
    "                        // Reduce connection timeout to 30 seconds (from 60s)\n",
    "                        HostContext.WritePerfCounter(\"ResetJobRenewConnection\");\n",
    "                        await runnerServer.RefreshConnectionAsync(RunnerConnectionType.JobRequest, TimeSpan.FromSeconds(30));\n",
    "\n",
    "                        try\n",
    "                        {\n",
    "                            // back-off before next retry.\n",
    "                            await HostContext.Delay(delayTime, token);\n",
    "                        }\n",
    "                        catch (OperationCanceledException) when (token.IsCancellationRequested)\n",
    "                        {\n",
    "                            Trace.Info($\"job renew has been canceled, stop renew job request {requestId}.\");\n",
    "                        }\n",
    "                    }\n",
    "                    else\n",
    "                    {\n",
    "                        Trace.Info($\"Lock renewal has run out of retry, stop renew lock for jobrequest {requestId}.\");\n",
    "                        HostContext.WritePerfCounter(\"JobRenewReachLimit\");\n",
    "                        return;\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'identifier'}\n",
      "['Task', 'RenewJobRequestAsync', 'poolId', 'requestId', 'Guid', 'lockToken', 'orchestrationId', 'TaskCompletionSource', 'firstJobRequestRenewed', 'CancellationToken', 'token', 'runnerServer', 'HostContext', 'GetService', 'IRunnerServer', 'TaskAgentJobRequest', 'request', 'firstRenewRetryLimit', 'encounteringError', 'token', 'IsCancellationRequested', 'request', 'runnerServer', 'RenewAgentRequestAsync', 'poolId', 'requestId', 'lockToken', 'orchestrationId', 'token', 'Trace', 'Info', 'requestId', 'request', 'LockedUntil', 'Value', 'firstJobRequestRenewed', 'Task', 'IsCompleted', 'firstJobRequestRenewed', 'TrySetResult', 'encounteringError', 'encounteringError', 'runnerServer', 'SetConnectionTimeout', 'RunnerConnectionType', 'JobRequest', 'TimeSpan', 'FromSeconds', 'HostContext', 'WritePerfCounter', 'HostContext', 'Delay', 'TimeSpan', 'FromSeconds', 'token', 'TaskAgentJobNotFoundException', 'Trace', 'Info', 'requestId', 'TaskAgentJobTokenExpiredException', 'Trace', 'Info', 'requestId', 'OperationCanceledException', 'token', 'IsCancellationRequested', 'Trace', 'Info', 'requestId', 'Exception', 'ex', 'Trace', 'Error', 'requestId', 'Trace', 'Error', 'ex', 'encounteringError', 'TimeSpan', 'remainingTime', 'TimeSpan', 'Zero', 'firstJobRequestRenewed', 'Task', 'IsCompleted', 'firstRenewRetryLimit', 'remainingTime', 'TimeSpan', 'FromSeconds', 'remainingTime', 'request', 'LockedUntil', 'Value', 'TimeSpan', 'FromMinutes', 'DateTime', 'UtcNow', 'remainingTime', 'TimeSpan', 'Zero', 'TimeSpan', 'delayTime', 'firstJobRequestRenewed', 'Task', 'IsCompleted', 'Trace', 'Info', 'requestId', 'delayTime', 'BackoffTimerHelper', 'GetRandomBackoff', 'TimeSpan', 'FromSeconds', 'TimeSpan', 'FromSeconds', 'Trace', 'Info', 'requestId', 'request', 'LockedUntil', 'Value', 'encounteringError', 'delayTime', 'BackoffTimerHelper', 'GetRandomBackoff', 'TimeSpan', 'FromSeconds', 'TimeSpan', 'FromSeconds', 'delayTime', 'BackoffTimerHelper', 'GetRandomBackoff', 'TimeSpan', 'FromSeconds', 'TimeSpan', 'FromSeconds', 'HostContext', 'WritePerfCounter', 'runnerServer', 'RefreshConnectionAsync', 'RunnerConnectionType', 'JobRequest', 'TimeSpan', 'FromSeconds', 'HostContext', 'Delay', 'delayTime', 'token', 'OperationCanceledException', 'token', 'IsCancellationRequested', 'Trace', 'Info', 'requestId', 'Trace', 'Info', 'requestId', 'HostContext', 'WritePerfCounter']\n"
     ]
    }
   ],
   "source": [
    "get_tokens(content, \"c_sharp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Token.Name.Function, Token.Name}\n",
      "['Task', 'RenewJobRequestAsync', 'poolId', 'requestId', 'Guid', 'lockToken', 'orchestrationId', 'TaskCompletionSource', 'firstJobRequestRenewed', 'CancellationToken', 'token', 'runnerServer', 'HostContext', 'GetService', 'IRunnerServer', 'TaskAgentJobRequest', 'request', 'firstRenewRetryLimit', 'encounteringError', 'token', 'IsCancellationRequested', 'request', 'runnerServer', 'RenewAgentRequestAsync', 'poolId', 'requestId', 'lockToken', 'orchestrationId', 'token', 'Trace', 'Info', 'firstJobRequestRenewed', 'Task', 'IsCompleted', 'firstJobRequestRenewed', 'TrySetResult', 'encounteringError', 'encounteringError', 'runnerServer', 'SetConnectionTimeout', 'RunnerConnectionType', 'JobRequest', 'TimeSpan', 'FromSeconds', 'HostContext', 'WritePerfCounter', 'HostContext', 'Delay', 'TimeSpan', 'FromSeconds', 'token', 'TaskAgentJobNotFoundException', 'Trace', 'Info', 'TaskAgentJobTokenExpiredException', 'Trace', 'Info', 'OperationCanceledException', 'when', 'token', 'IsCancellationRequested', 'Trace', 'Info', 'Exception', 'ex', 'Trace', 'Error', 'Trace', 'Error', 'ex', 'encounteringError', 'TimeSpan', 'remainingTime', 'TimeSpan', 'Zero', 'firstJobRequestRenewed', 'Task', 'IsCompleted', 'firstRenewRetryLimit', 'remainingTime', 'TimeSpan', 'FromSeconds', 'remainingTime', 'request', 'LockedUntil', 'Value', 'TimeSpan', 'FromMinutes', 'DateTime', 'UtcNow', 'remainingTime', 'TimeSpan', 'Zero', 'TimeSpan', 'delayTime', 'firstJobRequestRenewed', 'Task', 'IsCompleted', 'Trace', 'Info', 'delayTime', 'BackoffTimerHelper', 'GetRandomBackoff', 'TimeSpan', 'FromSeconds', 'TimeSpan', 'FromSeconds', 'Trace', 'Info', 'encounteringError', 'delayTime', 'BackoffTimerHelper', 'GetRandomBackoff', 'TimeSpan', 'FromSeconds', 'TimeSpan', 'FromSeconds', 'delayTime', 'BackoffTimerHelper', 'GetRandomBackoff', 'TimeSpan', 'FromSeconds', 'TimeSpan', 'FromSeconds', 'HostContext', 'WritePerfCounter', 'runnerServer', 'RefreshConnectionAsync', 'RunnerConnectionType', 'JobRequest', 'TimeSpan', 'FromSeconds', 'HostContext', 'Delay', 'delayTime', 'token', 'OperationCanceledException', 'when', 'token', 'IsCancellationRequested', 'Trace', 'Info', 'Trace', 'Info', 'HostContext', 'WritePerfCounter']\n"
     ]
    }
   ],
   "source": [
    "get_tokens_pygments(content, \"c-sharp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "#include \"memdebug.h\" /* keep this as LAST include */\n",
    "\n",
    "static void dump(const char *timebuf, const char *text,\n",
    "                 FILE *stream, const unsigned char *ptr, size_t size,\n",
    "                 trace tracetype, curl_infotype infotype);\n",
    "\n",
    "/*\n",
    "** callback for CURLOPT_DEBUGFUNCTION\n",
    "*/\n",
    "\n",
    "int tool_debug_cb(CURL *handle, curl_infotype type,\n",
    "                  char *data, size_t size,\n",
    "                  void *userdata)\n",
    "{\n",
    "  struct OperationConfig *operation = userdata;\n",
    "  struct GlobalConfig *config = operation->global;\n",
    "  FILE *output = config->errors;\n",
    "  const char *text;\n",
    "  struct timeval tv;\n",
    "  char timebuf[20];\n",
    "  time_t secs;\n",
    "\n",
    "  (void)handle; /* not used */\n",
    "\n",
    "  if(config->tracetime) {\n",
    "    struct tm *now;\n",
    "    static time_t epoch_offset;\n",
    "    static int    known_offset;\n",
    "    tv = tvnow();\n",
    "    if(!known_offset) {\n",
    "      epoch_offset = time(NULL) - tv.tv_sec;\n",
    "      known_offset = 1;\n",
    "    }\n",
    "    secs = epoch_offset + tv.tv_sec;\n",
    "    now = localtime(&secs);  /* not thread safe but we don't care */\n",
    "    msnprintf(timebuf, sizeof(timebuf), \"%02d:%02d:%02d.%06ld \",\n",
    "              now->tm_hour, now->tm_min, now->tm_sec, (long)tv.tv_usec);\n",
    "  }\n",
    "  else\n",
    "    timebuf[0] = 0;\n",
    "\n",
    "  if(!config->trace_stream) {\n",
    "    /* open for append */\n",
    "    if(!strcmp(\"-\", config->trace_dump))\n",
    "      config->trace_stream = stdout;\n",
    "    else if(!strcmp(\"%\", config->trace_dump))\n",
    "      /* Ok, this is somewhat hackish but we do it undocumented for now */\n",
    "      config->trace_stream = config->errors;  /* aka stderr */\n",
    "    else {\n",
    "      config->trace_stream = fopen(config->trace_dump, FOPEN_WRITETEXT);\n",
    "      config->trace_fopened = TRUE;\n",
    "    }\n",
    "  }\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type_identifier', 'identifier', 'field_identifier'}\n",
      "['dump', 'timebuf', 'text', 'FILE', 'stream', 'ptr', 'size', 'trace', 'tracetype', 'curl_infotype', 'infotype', 'tool_debug_cb', 'CURL', 'handle', 'curl_infotype', 'type', 'data', 'size', 'userdata', 'OperationConfig', 'operation', 'userdata', 'GlobalConfig', 'config', 'operation', 'global', 'FILE', 'output', 'config', 'errors', 'text', 'timeval', 'tv', 'timebuf', 'time_t', 'secs', 'handle', 'config', 'tracetime', 'tm', 'now', 'time_t', 'epoch_offset', 'known_offset', 'tv', 'tvnow', 'known_offset', 'epoch_offset', 'time', 'tv', 'tv_sec', 'known_offset', 'secs', 'epoch_offset', 'tv', 'tv_sec', 'now', 'localtime', 'secs', 'msnprintf', 'timebuf', 'timebuf', 'now', 'tm_hour', 'now', 'tm_min', 'now', 'tm_sec', 'tv', 'tv_usec', 'timebuf', 'config', 'trace_stream', 'strcmp', 'config', 'trace_dump', 'config', 'trace_stream', 'stdout', 'strcmp', 'config', 'trace_dump', 'config', 'trace_stream', 'config', 'errors', 'config', 'trace_stream', 'fopen', 'config', 'trace_dump', 'FOPEN_WRITETEXT', 'config', 'trace_fopened']\n"
     ]
    }
   ],
   "source": [
    "get_tokens(content, \"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Token.Name.Builtin, Token.Name.Function, Token.Name, Token.Comment.PreprocFile}\n",
      "['\"memdebug.h\" /* keep this as LAST include */', 'dump', 'timebuf', 'text', 'stream', 'ptr', 'size', 'trace', 'tracetype', 'curl_infotype', 'infotype', 'tool_debug_cb', 'CURL', 'handle', 'curl_infotype', 'type', 'data', 'size', 'userdata', 'OperationConfig', 'operation', 'userdata', 'GlobalConfig', 'config', 'operation', 'global', 'output', 'config', 'errors', 'text', 'timeval', 'tv', 'timebuf', 'secs', 'handle', 'config', 'tracetime', 'tm', 'now', 'epoch_offset', 'known_offset', 'tv', 'tvnow', 'known_offset', 'epoch_offset', 'time', 'NULL', 'tv', 'tv_sec', 'known_offset', 'secs', 'epoch_offset', 'tv', 'tv_sec', 'now', 'localtime', 'secs', 'msnprintf', 'timebuf', 'timebuf', 'now', 'tm_hour', 'now', 'tm_min', 'now', 'tm_sec', 'tv', 'tv_usec', 'timebuf', 'config', 'trace_stream', 'strcmp', 'config', 'trace_dump', 'config', 'trace_stream', 'stdout', 'strcmp', 'config', 'trace_dump', 'config', 'trace_stream', 'config', 'errors', 'config', 'trace_stream', 'fopen', 'config', 'trace_dump', 'FOPEN_WRITETEXT', 'config', 'trace_fopened', 'TRUE']\n"
     ]
    }
   ],
   "source": [
    "get_tokens_pygments(content, \"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "package com.spotify.scio.testing.util\n",
    "\n",
    "import java.io.IOException\n",
    "import java.nio.file.FileAlreadyExistsException\n",
    "\n",
    "import com.google.api.client.util.Sleeper\n",
    "import com.google.api.services.cloudresourcemanager.CloudResourceManager\n",
    "import com.google.api.services.storage.model.Bucket\n",
    "import com.google.cloud.hadoop.util.{ResilientOperation, RetryDeterminer}\n",
    "import org.apache.beam.sdk.extensions.gcp.options.{GcpOptions, GcsOptions}\n",
    "import org.apache.beam.sdk.options.PipelineOptions\n",
    "import org.apache.beam.sdk.extensions.gcp.util.gcsfs.GcsPath\n",
    "import org.apache.beam.sdk.extensions.gcp.util.BackOffAdapter\n",
    "import org.apache.beam.sdk.util.{BackOff, FluentBackoff}\n",
    "import org.joda.time.Duration\n",
    "import org.slf4j.{Logger, LoggerFactory}\n",
    "\n",
    "private object DefaultBucket {\n",
    "  private[this] val isNullOrEmpty: String => Boolean = s => !Option(s).exists(_.nonEmpty)\n",
    "\n",
    "  def tryCreateDefaultBucket(options: PipelineOptions, crmClient: CloudResourceManager): String = {\n",
    "    val gcpOptions = options.as(classOf[GcsOptions])\n",
    "    val projectId = gcpOptions.getProject\n",
    "    require(!isNullOrEmpty(projectId), \"--project is a required option.\")\n",
    "    // Look up the project number, to create a default bucket with a stable\n",
    "    // name with no special characters.\n",
    "    var projectNumber = 0L\n",
    "    try projectNumber = getProjectNumber(projectId, crmClient)\n",
    "    catch {\n",
    "      case e: IOException =>\n",
    "        throw new RuntimeException(\"Unable to verify project with ID \" + projectId, e)\n",
    "    }\n",
    "    var region = DEFAULT_REGION\n",
    "    if (!isNullOrEmpty(gcpOptions.getZone)) region = getRegionFromZone(gcpOptions.getZone)\n",
    "    val bucketName = \"dataflow-staging-\" + region + \"-\" + projectNumber\n",
    "    LOG.info(\"No staging location provided, attempting to use default bucket: {}\", bucketName)\n",
    "    val bucket = new Bucket().setName(bucketName).setLocation(region)\n",
    "    // Always try to create the bucket before checking access, so that we do not\n",
    "    // race with other pipelines that may be attempting to do the same thing.\n",
    "    try gcpOptions.getGcsUtil.createBucket(projectId, bucket)\n",
    "    catch {\n",
    "      case e: FileAlreadyExistsException =>\n",
    "        LOG.debug(\"Bucket '{}'' already exists, verifying access.\", bucketName)\n",
    "      case e: IOException =>\n",
    "        throw new RuntimeException(\"Unable create default bucket.\", e)\n",
    "    }\n",
    "    // Once the bucket is expected to exist, verify that it is correctly owned\n",
    "    // by the project executing the job.\n",
    "    try {\n",
    "      val owner = gcpOptions.getGcsUtil.bucketOwner(GcsPath.fromComponents(bucketName, \"\"))\n",
    "      require(\n",
    "        owner == projectNumber,\n",
    "        s\"Bucket owner does not match the project from --project: $owner vs. $projectNumber\"\n",
    "      )\n",
    "    } catch {\n",
    "      case e: IOException =>\n",
    "        throw new RuntimeException(\n",
    "          \"Unable to determine the owner of the default bucket at gs://\" +\n",
    "            bucketName,\n",
    "          e\n",
    "        )\n",
    "    }\n",
    "    \"gs://\" + bucketName\n",
    "  }\n",
    "\n",
    "  private val BACKOFF_FACTORY = FluentBackoff.DEFAULT\n",
    "    .withMaxRetries(3)\n",
    "    .withInitialBackoff(Duration.millis(200))\n",
    "\n",
    "  private val DEFAULT_REGION = \"us-central1\"\n",
    "  private val LOG: Logger = LoggerFactory.getLogger(classOf[GcpOptions.GcpTempLocationFactory])\n",
    "\n",
    "  private def getProjectNumber(projectId: String, crmClient: CloudResourceManager): Long =\n",
    "    getProjectNumber(projectId, crmClient, BACKOFF_FACTORY.backoff(), Sleeper.DEFAULT)\n",
    "\n",
    "  private def getProjectNumber(\n",
    "    projectId: String,\n",
    "    crmClient: CloudResourceManager,\n",
    "    backoff: BackOff,\n",
    "    sleeper: Sleeper\n",
    "  ): Long = {\n",
    "    val getProject = crmClient.projects.get(projectId)\n",
    "    try {\n",
    "      val project = ResilientOperation.retry(\n",
    "        ResilientOperation.getGoogleRequestCallable(getProject),\n",
    "        BackOffAdapter.toGcpBackOff(backoff),\n",
    "        RetryDeterminer.SOCKET_ERRORS,\n",
    "        classOf[IOException],\n",
    "        sleeper\n",
    "      )\n",
    "      project.getProjectNumber\n",
    "    } catch {\n",
    "      case e: Exception =>\n",
    "        throw new IOException(\"Unable to get project number\", e)\n",
    "    }\n",
    "  }\n",
    "\n",
    "  private def getRegionFromZone(zone: String): String = {\n",
    "    val zoneParts = zone.split(\"-\")\n",
    "    require(zoneParts.length >= 2, s\"Invalid zone provided: $zone\")\n",
    "    zoneParts(0) + \"-\" + zoneParts(1)\n",
    "  }\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'package_identifier', 'type_identifier', 'identifier'}\n",
      "['com.spotify.scio.testing.util', 'com', 'spotify', 'scio', 'testing', 'util', 'java', 'io', 'IOException', 'java', 'nio', 'file', 'FileAlreadyExistsException', 'com', 'google', 'api', 'client', 'util', 'Sleeper', 'com', 'google', 'api', 'services', 'cloudresourcemanager', 'CloudResourceManager', 'com', 'google', 'api', 'services', 'storage', 'model', 'Bucket', 'com', 'google', 'cloud', 'hadoop', 'util', 'ResilientOperation', 'RetryDeterminer', 'org', 'apache', 'beam', 'sdk', 'extensions', 'gcp', 'options', 'GcpOptions', 'GcsOptions', 'org', 'apache', 'beam', 'sdk', 'options', 'PipelineOptions', 'org', 'apache', 'beam', 'sdk', 'extensions', 'gcp', 'util', 'gcsfs', 'GcsPath', 'org', 'apache', 'beam', 'sdk', 'extensions', 'gcp', 'util', 'BackOffAdapter', 'org', 'apache', 'beam', 'sdk', 'util', 'BackOff', 'FluentBackoff', 'org', 'joda', 'time', 'Duration', 'org', 'slf4j', 'Logger', 'LoggerFactory', 'DefaultBucket', 'this', 'isNullOrEmpty', 'String', 'Boolean', 's', 'Option', 's', 'exists', '_', 'nonEmpty', 'tryCreateDefaultBucket', 'options', 'PipelineOptions', 'crmClient', 'CloudResourceManager', 'String', 'gcpOptions', 'options', 'as', 'classOf', 'GcsOptions', 'projectId', 'gcpOptions', 'getProject', 'require', 'isNullOrEmpty', 'projectId', 'projectNumber', 'L', 'projectNumber', 'getProjectNumber', 'projectId', 'crmClient', 'catch', 'case', 'e', 'IOException', 'throw', 'new', 'RuntimeException', 'projectId', 'e', 'region', 'DEFAULT_REGION', 'if', 'isNullOrEmpty', 'gcpOptions', 'getZone', 'region', 'getRegionFromZone', 'gcpOptions', 'getZone', 'bucketName', 'region', 'projectNumber', 'LOG', 'info', 'bucketName', 'bucket', 'Bucket', 'setName', 'bucketName', 'setLocation', 'region', 'try', 'gcpOptions', 'getGcsUtil', 'createBucket', 'projectId', 'bucket', 'catch', 'e', 'FileAlreadyExistsException', 'LOG', 'debug', 'bucketName', 'e', 'IOException', 'throw', 'new', 'RuntimeException', 'e', 'try', 'owner', 'gcpOptions', 'getGcsUtil', 'bucketOwner', 'GcsPath', 'fromComponents', 'bucketName', 'require', 'owner', 'projectNumber', 's', 'owner', 'projectNumber', 'catch', 'e', 'IOException', 'throw', 'new', 'RuntimeException', 'bucketName', 'e', 'bucketName', '', 'BACKOFF_FACTORY', 'FluentBackoff', 'DEFAULT', 'withMaxRetries', 'withInitialBackoff', 'Duration', 'millis', 'DEFAULT_REGION', 'LOG', 'Logger', 'LoggerFactory', 'getLogger', 'classOf', 'GcpOptions', 'GcpTempLocationFactory', 'getProjectNumber', 'projectId', 'String', 'crmClient', 'CloudResourceManager', 'Long', 'getProjectNumber', 'projectId', 'crmClient', 'BACKOFF_FACTORY', 'backoff', 'Sleeper', 'DEFAULT', 'getProjectNumber', 'projectId', 'String', 'crmClient', 'CloudResourceManager', 'backoff', 'BackOff', 'sleeper', 'Sleeper', 'Long', 'getProject', 'crmClient', 'projects', 'get', 'projectId', 'project', 'ResilientOperation', 'retry', 'ResilientOperation', 'getGoogleRequestCallable', 'getProject', 'BackOffAdapter', 'toGcpBackOff', 'backoff', 'RetryDeterminer', 'SOCKET_ERRORS', 'classOf', 'IOException', 'sleeper', 'project', 'getProjectNumber', 'e', 'Exception', 'throw', 'new', 'IOException', 'e', 'getRegionFromZone', 'zone', 'String', 'String', 'zoneParts', 'zone', 'split', 'require', 'zoneParts', 'length', 's', 'zone', 'zoneParts', 'zoneParts', '']\n"
     ]
    }
   ],
   "source": [
    "get_tokens(content, \"scala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Token.Name.Namespace, Token.Name, Token.Name.Class}\n",
      "['com.spotify.scio.testing.util', 'java.io.IOException', 'java.nio.file.FileAlreadyExistsException', 'com.google.api.client.util.Sleeper', 'com.google.api.services.cloudresourcemanager.CloudResourceManager', 'com.google.api.services.storage.model.Bucket', 'com.google.cloud.hadoop.util.', 'ResilientOperation', 'RetryDeterminer', 'org.apache.beam.sdk.extensions.gcp.options.', 'GcpOptions', 'GcsOptions', 'org.apache.beam.sdk.options.PipelineOptions', 'org.apache.beam.sdk.extensions.gcp.util.gcsfs.GcsPath', 'org.apache.beam.sdk.extensions.gcp.util.BackOffAdapter', 'org.apache.beam.sdk.util.', 'BackOff', 'FluentBackoff', 'org.joda.time.Duration', 'org.slf4j.', 'Logger', 'LoggerFactory', 'DefaultBucket', 'isNullOrEmpty', 'Boolean', 's', 'Option', 's', 'exists', 'nonEmpty', 'tryCreateDefaultBucket', 'options', 'crmClient', 'gcpOptions', 'options', 'as', 'classOf', 'projectId', 'gcpOptions', 'getProject', 'require', 'isNullOrEmpty', 'projectId', 'projectNumber', 'projectNumber', 'getProjectNumber', 'projectId', 'crmClient', 'e', 'RuntimeException', 'projectId', 'e', 'region', 'DEFAULT_REGION', 'isNullOrEmpty', 'gcpOptions', 'getZone', 'region', 'getRegionFromZone', 'gcpOptions', 'getZone', 'bucketName', 'region', 'projectNumber', 'LOG', 'info', 'bucketName', 'bucket', 'Bucket', 'setName', 'bucketName', 'setLocation', 'region', 'gcpOptions', 'getGcsUtil', 'createBucket', 'projectId', 'bucket', 'e', 'LOG', 'debug', 'bucketName', 'e', 'RuntimeException', 'e', 'owner', 'gcpOptions', 'getGcsUtil', 'bucketOwner', 'GcsPath', 'fromComponents', 'bucketName', 'require', 'owner', 'projectNumber', 'e', 'RuntimeException', 'bucketName', 'e', 'bucketName', 'BACKOFF_FACTORY', 'FluentBackoff', 'DEFAULT', 'withMaxRetries', 'withInitialBackoff', 'Duration', 'millis', 'DEFAULT_REGION', 'LOG', 'LoggerFactory', 'getLogger', 'classOf', 'getProjectNumber', 'projectId', 'crmClient', 'getProjectNumber', 'projectId', 'crmClient', 'BACKOFF_FACTORY', 'backoff', 'Sleeper', 'DEFAULT', 'getProjectNumber', 'projectId', 'crmClient', 'backoff', 'sleeper', 'getProject', 'crmClient', 'projects', 'get', 'projectId', 'project', 'ResilientOperation', 'retry', 'ResilientOperation', 'getGoogleRequestCallable', 'getProject', 'BackOffAdapter', 'toGcpBackOff', 'backoff', 'RetryDeterminer', 'SOCKET_ERRORS', 'classOf', 'sleeper', 'project', 'getProjectNumber', 'e', 'IOException', 'e', 'getRegionFromZone', 'zone', 'zoneParts', 'zone', 'split', 'require', 'zoneParts', 'length', 'zoneParts', 'zoneParts']\n"
     ]
    }
   ],
   "source": [
    "get_tokens_pygments(content, \"scala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "EXEC_FILES=\"git-flow\"\n",
    "SCRIPT_FILES=\"git-flow-init git-flow-feature git-flow-hotfix git-flow-release git-flow-support git-flow-version gitflow-common gitflow-shFlags\"\n",
    "SUBMODULE_FILE=\"gitflow-shFlags\"\n",
    "\n",
    "echo \"### gitflow no-make installer ###\"\n",
    "\n",
    "case \"$1\" in\n",
    "\tuninstall)\n",
    "\t\techo \"Uninstalling git-flow from $INSTALL_PREFIX\"\n",
    "\t\tif [ -d \"$INSTALL_PREFIX\" ] ; then\n",
    "\t\t\tfor script_file in $SCRIPT_FILES $EXEC_FILES ; do\n",
    "\t\t\t\techo \"rm -vf $INSTALL_PREFIX/$script_file\"\n",
    "\t\t\t\trm -vf \"$INSTALL_PREFIX/$script_file\"\n",
    "\t\t\tdone\n",
    "\t\telse\n",
    "\t\t\techo \"The '$INSTALL_PREFIX' directory was not found.\"\n",
    "\t\t\techo \"Do you need to set INSTALL_PREFIX ?\"\n",
    "\t\tfi\n",
    "\t\texit\n",
    "\t\t;;\n",
    "\thelp)\n",
    "\t\techo \"Usage: [environment] gitflow-installer.sh [install|uninstall]\"\n",
    "\t\techo \"Environment:\"\n",
    "\t\techo \"   INSTALL_PREFIX=$INSTALL_PREFIX\"\n",
    "\t\techo \"   REPO_HOME=$REPO_HOME\"\n",
    "\t\techo \"   REPO_NAME=$REPO_NAME\"\n",
    "\t\texit\n",
    "\t\t;;\n",
    "\t*)\n",
    "\t\techo \"Installing git-flow to $INSTALL_PREFIX\"\n",
    "\t\tif [ -d \"$REPO_NAME\" -a -d \"$REPO_NAME/.git\" ] ; then\n",
    "\t\t\techo \"Using existing repo: $REPO_NAME\"\n",
    "\t\telse\n",
    "\t\t\techo \"Cloning repo from GitHub to $REPO_NAME\"\n",
    "\t\t\tgit clone \"$REPO_HOME\" \"$REPO_NAME\"\n",
    "\t\tfi\n",
    "\t\tif [ -f \"$REPO_NAME/$SUBMODULE_FILE\" ] ; then\n",
    "\t\t\techo \"Submodules look up to date\"\n",
    "\t\telse\n",
    "\t\t\techo \"Updating submodules\"\n",
    "\t\t\tlastcwd=$PWD\n",
    "\t\t\tcd \"$REPO_NAME\"\n",
    "\t\t\tgit submodule init\n",
    "\t\t\tgit submodule update\n",
    "\t\t\tcd \"$lastcwd\"\n",
    "\t\tfi\n",
    "\t\tinstall -v -d -m 0755 \"$INSTALL_PREFIX\"\n",
    "\t\tfor exec_file in $EXEC_FILES ; do\n",
    "\t\t\tinstall -v -m 0755 \"$REPO_NAME/$exec_file\" \"$INSTALL_PREFIX\"\n",
    "\t\tdone\n",
    "\t\tfor script_file in $SCRIPT_FILES ; do\n",
    "\t\t\tinstall -v -m 0644 \"$REPO_NAME/$script_file\" \"$INSTALL_PREFIX\"\n",
    "\t\tdone\n",
    "\t\texit\n",
    "\t\t;;\n",
    "esac\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'variable_name', 'command_name'}\n",
      "['EXEC_FILES', 'SCRIPT_FILES', 'SUBMODULE_FILE', 'echo', '1', 'echo', 'INSTALL_PREFIX', 'INSTALL_PREFIX', 'script_file', 'SCRIPT_FILES', 'EXEC_FILES', 'echo', 'INSTALL_PREFIX', 'script_file', 'rm', 'INSTALL_PREFIX', 'script_file', 'echo', 'INSTALL_PREFIX', 'echo', 'exit', 'echo', 'echo', 'echo', 'INSTALL_PREFIX', 'echo', 'REPO_HOME', 'echo', 'REPO_NAME', 'exit', 'echo', 'INSTALL_PREFIX', 'REPO_NAME', 'REPO_NAME', 'echo', 'REPO_NAME', 'echo', 'REPO_NAME', 'git', 'REPO_HOME', 'REPO_NAME', 'REPO_NAME', 'SUBMODULE_FILE', 'echo', 'echo', 'lastcwd', 'PWD', 'cd', 'REPO_NAME', 'git', 'git', 'cd', 'lastcwd', 'install', 'INSTALL_PREFIX', 'exec_file', 'EXEC_FILES', 'install', 'REPO_NAME', 'exec_file', 'INSTALL_PREFIX', 'script_file', 'SCRIPT_FILES', 'install', 'REPO_NAME', 'script_file', 'INSTALL_PREFIX', 'exit']\n"
     ]
    }
   ],
   "source": [
    "get_tokens(content, \"bash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Token.Name.Builtin, Token.Name.Variable}\n",
      "['EXEC_FILES', 'SCRIPT_FILES', 'SUBMODULE_FILE', 'echo', '$1', 'echo', '$INSTALL_PREFIX', '$INSTALL_PREFIX', '$SCRIPT_FILES', '$EXEC_FILES', 'echo', '$INSTALL_PREFIX', '$script_file', '$INSTALL_PREFIX', '$script_file', 'echo', '$INSTALL_PREFIX', 'echo', 'exit', 'help', 'echo', 'echo', 'echo', '$INSTALL_PREFIX', 'echo', '$REPO_HOME', 'echo', '$REPO_NAME', 'exit', 'echo', '$INSTALL_PREFIX', '$REPO_NAME', '$REPO_NAME', 'echo', '$REPO_NAME', 'echo', '$REPO_NAME', '$REPO_HOME', '$REPO_NAME', '$REPO_NAME', '$SUBMODULE_FILE', 'echo', 'echo', 'lastcwd', '$PWD', 'cd', '$REPO_NAME', 'cd', '$lastcwd', '$INSTALL_PREFIX', '$EXEC_FILES', '$REPO_NAME', '$exec_file', '$INSTALL_PREFIX', '$SCRIPT_FILES', '$REPO_NAME', '$script_file', '$INSTALL_PREFIX', 'exit']\n"
     ]
    }
   ],
   "source": [
    "get_tokens_pygments(content, \"bash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "#[macro_use]\n",
    "extern crate structopt;\n",
    "\n",
    "use std::fs::File;\n",
    "use std::io;\n",
    "use std::io::Write;\n",
    "use std::path::Path;\n",
    "\n",
    "use ray;\n",
    "\n",
    "#[derive(StructOpt)]\n",
    "struct Args {\n",
    "    #[structopt(short = \"f\")]\n",
    "    /// The file to output the image to\n",
    "    file_out: Option<String>,\n",
    "\n",
    "    #[structopt(short = \"m\", long = \"height\", default_value = \"200\")]\n",
    "    /// The height\n",
    "    height: i32,\n",
    "\n",
    "    #[structopt(short = \"n\", long = \"width\", default_value = \"200\")]\n",
    "    /// The width\n",
    "    width: i32,\n",
    "\n",
    "    #[structopt(short = \"s\", long = \"scene\", default_value = \"rgbbox\")]\n",
    "    /// The scene to show. Possible values are 'rgbbox' and 'irreg'\n",
    "    scene_name: String,\n",
    "}\n",
    "\n",
    "#[paw::main]\n",
    "fn main(args: Args) -> Result<(), Box<dyn std::error::Error>> {\n",
    "    let mut scene = match args.scene_name.as_ref() {\n",
    "        \"irreg\" => (*ray::sample_scenes::IRREG).clone(),\n",
    "        \"rgbbox\" => (*ray::sample_scenes::RGBBOX).clone(),\n",
    "        s => panic!(\"Invalid scene: {}\", s),\n",
    "    };\n",
    "\n",
    "    let (objs, cam) = ray::from_scene(args.width, args.height, &mut scene);\n",
    "\n",
    "    let result = ray::render(&objs, args.width, args.height, &cam);\n",
    "\n",
    "    let out_writer = match args.file_out {\n",
    "        Some(x) => {\n",
    "            let path = Path::new(&x);\n",
    "            Box::new(File::create(&path).unwrap()) as Box<dyn Write>\n",
    "        }\n",
    "        None => Box::new(io::stdout()) as Box<dyn Write>,\n",
    "    };\n",
    "\n",
    "    ray::image2ppm(out_writer, result)?;\n",
    "\n",
    "    Ok(())\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type_identifier', 'identifier', 'field_identifier'}\n",
      "['macro_use', 'structopt', 'std', 'fs', 'File', 'std', 'io', 'std', 'io', 'Write', 'std', 'path', 'Path', 'ray', 'derive', 'StructOpt', 'Args', 'structopt', 'short', 'file_out', 'Option', 'String', 'structopt', 'short', 'long', 'default_value', 'height', 'structopt', 'short', 'long', 'default_value', 'width', 'structopt', 'short', 'long', 'default_value', 'scene_name', 'String', 'paw', 'main', 'main', 'args', 'Args', 'Result', 'Box', 'std', 'error', 'Error', 'scene', 'args', 'scene_name', 'as_ref', 'ray', 'sample_scenes', 'IRREG', 'clone', 'ray', 'sample_scenes', 'RGBBOX', 'clone', 's', 'panic', 's', 'objs', 'cam', 'ray', 'from_scene', 'args', 'width', 'args', 'height', 'scene', 'result', 'ray', 'render', 'objs', 'args', 'width', 'args', 'height', 'cam', 'out_writer', 'args', 'file_out', 'Some', 'x', 'path', 'Path', 'new', 'x', 'Box', 'new', 'File', 'create', 'path', 'unwrap', 'Box', 'Write', 'None', 'Box', 'new', 'io', 'stdout', 'Box', 'Write', 'ray', 'image2ppm', 'out_writer', 'result', 'Ok']\n"
     ]
    }
   ],
   "source": [
    "get_tokens(content, \"rust\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Token.Name.Builtin, Token.Name.Function, Token.Name, Token.Name.Class}\n",
      "['structopt', 'std', 'fs', 'File', 'std', 'io', 'std', 'io', 'Write', 'std', 'path', 'Path', 'ray', 'Args', 'file_out', 'Option', 'String', 'height', 'width', 'scene_name', 'String', 'main', 'args', 'Args', 'Result', 'Box', 'dyn', 'std', 'error', 'Error', 'scene', 'args', 'scene_name', 'as_ref', 'ray', 'sample_scenes', 'IRREG', 'clone', 'ray', 'sample_scenes', 'RGBBOX', 'clone', 's', 'panic', 's', 'objs', 'cam', 'ray', 'from_scene', 'args', 'width', 'args', 'height', 'scene', 'result', 'ray', 'render', 'objs', 'args', 'width', 'args', 'height', 'cam', 'out_writer', 'args', 'file_out', 'Some', 'x', 'path', 'Path', 'new', 'x', 'Box', 'new', 'File', 'create', 'path', 'unwrap', 'Box', 'dyn', 'Write', 'None', 'Box', 'new', 'io', 'stdout', 'Box', 'dyn', 'Write', 'ray', 'image2ppm', 'out_writer', 'result', 'Ok']\n"
     ]
    }
   ],
   "source": [
    "get_tokens_pygments(content, \"rust\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "extension DataStreamRequest {\n",
    "    /// A closure used to validate a request that takes a `URLRequest` and `HTTPURLResponse` and returns whether the\n",
    "    /// request was valid.\n",
    "    public typealias Validation = (_ request: URLRequest?, _ response: HTTPURLResponse) -> ValidationResult\n",
    "\n",
    "    /// Validates that the response has a status code in the specified sequence.\n",
    "    ///\n",
    "    /// If validation fails, subsequent calls to response handlers will have an associated error.\n",
    "    ///\n",
    "    /// - Parameter statusCode: `Sequence` of acceptable response status codes.\n",
    "    ///\n",
    "    /// - Returns:              The instance.\n",
    "    @discardableResult\n",
    "    public func validate<S: Sequence>(statusCode acceptableStatusCodes: S) -> Self where S.Iterator.Element == Int {\n",
    "        return validate { [unowned self] _, response in\n",
    "            self.validate(statusCode: acceptableStatusCodes, response: response)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    /// Validates that the response has a content type in the specified sequence.\n",
    "    ///\n",
    "    /// If validation fails, subsequent calls to response handlers will have an associated error.\n",
    "    ///\n",
    "    /// - parameter contentType: The acceptable content types, which may specify wildcard types and/or subtypes.\n",
    "    ///\n",
    "    /// - returns: The request.\n",
    "    @discardableResult\n",
    "    public func validate<S: Sequence>(contentType acceptableContentTypes: @escaping @autoclosure () -> S) -> Self where S.Iterator.Element == String {\n",
    "        return validate { [unowned self] _, response in\n",
    "            self.validate(contentType: acceptableContentTypes(), response: response)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    /// Validates that the response has a status code in the default acceptable range of 200...299, and that the content\n",
    "    /// type matches any specified in the Accept HTTP header field.\n",
    "    ///\n",
    "    /// If validation fails, subsequent calls to response handlers will have an associated error.\n",
    "    ///\n",
    "    /// - Returns: The instance.\n",
    "    @discardableResult\n",
    "    public func validate() -> Self {\n",
    "        validate(statusCode: acceptableStatusCodes).validate(contentType: self.acceptableContentTypes)\n",
    "    }\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type_identifier', 'identifier'}\n",
      "['DataStreamRequest', 'Validation', '_', 'request', 'URLRequest', '_', 'response', 'HTTPURLResponse', 'ValidationResult', 'discardableResult', 'validate', 'S', 'Sequence', 'statusCode', 'acceptableStatusCodes', 'S', 'Self', 'where', 'S', 'Iterator', 'Element', 'validate', 'unowned', 'self', 'response', 'in', 'self', 'validate', 'statusCode', 'acceptableStatusCodes', 'response', 'response', 'discardableResult', 'validate', 'S', 'Sequence', 'contentType', 'acceptableContentTypes', 'escaping', 'autoclosure', 'S', 'Self', 'where', 'S', 'Iterator', 'Element', 'validate', 'unowned', 'self', 'response', 'in', 'self', 'validate', 'contentType', 'acceptableContentTypes', 'response', 'response', 'discardableResult', 'validate', 'Self', 'validate', 'statusCode', 'acceptableStatusCodes', 'validate', 'contentType', 'self', 'acceptableContentTypes']\n"
     ]
    }
   ],
   "source": [
    "get_tokens(content, \"swift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Token.Name.Builtin, Token.Name.Function, Token.Name, Token.Name.Class}\n",
      "['DataStreamRequest', 'Validation', 'request', 'URLRequest', 'response', 'HTTPURLResponse', 'ValidationResult', 'discardableResult', 'validate', 'S', 'Sequence', 'statusCode', 'acceptableStatusCodes', 'S', 'S', 'Iterator', 'Element', 'Int', 'validate', 'response', 'validate', 'statusCode', 'acceptableStatusCodes', 'response', 'response', 'discardableResult', 'validate', 'S', 'Sequence', 'contentType', 'acceptableContentTypes', 'escaping', 'S', 'S', 'Iterator', 'Element', 'String', 'validate', 'response', 'validate', 'contentType', 'acceptableContentTypes', 'response', 'response', 'discardableResult', 'validate', 'validate', 'statusCode', 'acceptableStatusCodes', 'validate', 'contentType', 'acceptableContentTypes']\n"
     ]
    }
   ],
   "source": [
    "get_tokens_pygments(content, \"swift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "package org.jetbrains.exposed.sql.statements.jdbc\n",
    "\n",
    "import org.jetbrains.exposed.sql.ColumnType\n",
    "import org.jetbrains.exposed.sql.Transaction\n",
    "import org.jetbrains.exposed.sql.statements.Statement\n",
    "import org.jetbrains.exposed.sql.statements.StatementType\n",
    "import org.jetbrains.exposed.sql.statements.api.ExposedConnection\n",
    "import org.jetbrains.exposed.sql.statements.api.ExposedDatabaseMetadata\n",
    "import org.jetbrains.exposed.sql.statements.api.ExposedSavepoint\n",
    "import org.jetbrains.exposed.sql.statements.api.PreparedStatementApi\n",
    "import org.jetbrains.exposed.sql.transactions.TransactionManager\n",
    "import java.sql.Connection\n",
    "import java.sql.PreparedStatement\n",
    "\n",
    "class JdbcConnectionImpl(override val connection: Connection) : ExposedConnection<Connection> {\n",
    "\n",
    "    // Oracle driver could throw excpection on catalog\n",
    "    override var catalog: String\n",
    "        get() =  try { connection.catalog } catch (_: Exception) { null } ?: connection.metaData.userName ?: \"\"\n",
    "        set(value) { try { connection.catalog = value } catch (_: Exception) {} }\n",
    "\n",
    "    override var schema: String\n",
    "        get() =  try { connection.schema } catch (_: Exception) { \"\" }\n",
    "        set(value) { try { connection.schema = value } catch (_: Exception) {} }\n",
    "\n",
    "    override fun commit() {\n",
    "        connection.commit()\n",
    "    }\n",
    "\n",
    "    override fun rollback() {\n",
    "        connection.rollback()\n",
    "    }\n",
    "\n",
    "    override val isClosed get() = connection.isClosed\n",
    "    override fun close() {\n",
    "        connection.close()\n",
    "    }\n",
    "\n",
    "    override var autoCommit: Boolean\n",
    "        get() = connection.autoCommit\n",
    "        set(value) { connection.autoCommit = value }\n",
    "\n",
    "    override var transactionIsolation: Int\n",
    "        get() = connection.transactionIsolation\n",
    "        set(value) { connection.transactionIsolation = value }\n",
    "\n",
    "    private val metadata by lazy {\n",
    "        JdbcDatabaseMetadataImpl(catalog, connection.metaData)\n",
    "    }\n",
    "\n",
    "    override fun <T> metadata(body: ExposedDatabaseMetadata.() -> T): T = metadata.body()\n",
    "\n",
    "    override fun prepareStatement(sql: String, returnKeys: Boolean) : PreparedStatementApi {\n",
    "        val generated = if (returnKeys)\n",
    "            PreparedStatement.RETURN_GENERATED_KEYS\n",
    "        else\n",
    "            PreparedStatement.NO_GENERATED_KEYS\n",
    "        return JdbcPreparedStatementImpl(connection.prepareStatement(sql, generated), returnKeys)\n",
    "    }\n",
    "\n",
    "    override fun prepareStatement(sql: String, columns: Array<String>): PreparedStatementApi {\n",
    "        return JdbcPreparedStatementImpl(connection.prepareStatement(sql, columns), true)\n",
    "    }\n",
    "\n",
    "    override fun executeInBatch(sqls: List<String>) {\n",
    "        val types = sqls.map { stmt ->\n",
    "            StatementType.values().find {\n",
    "                stmt.startsWith(it.name, true)\n",
    "            } ?: StatementType.OTHER\n",
    "        }\n",
    "\n",
    "        check(types.none { it == StatementType.SELECT }) {\n",
    "            \"SELECT statements are unsupported in batch execution\"\n",
    "        }\n",
    "\n",
    "        val type = types.distinct().singleOrNull() ?: StatementType.OTHER\n",
    "        val prepStatement = object : Statement<Unit>(type, emptyList()) {\n",
    "\n",
    "            override fun prepared(transaction: Transaction, sql: String): PreparedStatementApi {\n",
    "                val originalStatement = super.prepared(transaction, sql.substringBefore('\\n'))\n",
    "                val batchStatement = connection.createStatement().apply {\n",
    "                    sqls.forEach {\n",
    "                        addBatch(it)\n",
    "                    }\n",
    "                }\n",
    "                return object : PreparedStatementApi by originalStatement {\n",
    "                    override fun closeIfPossible() {\n",
    "                        batchStatement.close()\n",
    "                        originalStatement.closeIfPossible()\n",
    "                    }\n",
    "\n",
    "                    override fun executeUpdate(): Int {\n",
    "                        batchStatement.executeBatch()\n",
    "                        return 0\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "            override fun PreparedStatementApi.executeInternal(transaction: Transaction) {\n",
    "                executeUpdate()\n",
    "            }\n",
    "\n",
    "            override fun prepareSQL(transaction: Transaction): String = sqls.joinToString(\"\\n\")\n",
    "\n",
    "            override fun arguments(): Iterable<Iterable<Pair<ColumnType, Any?>>> = emptyList()\n",
    "        }\n",
    "\n",
    "        prepStatement.execute(TransactionManager.current())\n",
    "    }\n",
    "\n",
    "    override fun setSavepoint(name: String): ExposedSavepoint {\n",
    "        return JdbcSavepoint(name, connection.setSavepoint(name))\n",
    "    }\n",
    "\n",
    "    override fun releaseSavepoint(savepoint: ExposedSavepoint) {\n",
    "        connection.releaseSavepoint((savepoint as JdbcSavepoint).savepoint)\n",
    "    }\n",
    "\n",
    "    override fun rollback(savepoint: ExposedSavepoint) {\n",
    "        connection.rollback((savepoint as JdbcSavepoint).savepoint)\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Token.Name.Property, Token.Name.Namespace, Token.Name, Token.Name.Function, Token.Name.Class}\n",
      "['org.jetbrains.exposed.sql.statements.jdbc', 'org.jetbrains.exposed.sql.ColumnType', 'org.jetbrains.exposed.sql.Transaction', 'org.jetbrains.exposed.sql.statements.Statement', 'org.jetbrains.exposed.sql.statements.StatementType', 'org.jetbrains.exposed.sql.statements.api.ExposedConnection', 'org.jetbrains.exposed.sql.statements.api.ExposedDatabaseMetadata', 'org.jetbrains.exposed.sql.statements.api.ExposedSavepoint', 'org.jetbrains.exposed.sql.statements.api.PreparedStatementApi', 'org.jetbrains.exposed.sql.transactions.TransactionManager', 'java.sql.Connection', 'java.sql.PreparedStatement', 'JdbcConnectionImpl', 'connection', 'Connection', 'ExposedConnection', 'Connection', 'catalog', 'String', 'connection', 'catalog', '_', 'Exception', 'connection', 'metaData', 'userName', 'value', 'connection', 'catalog', 'value', '_', 'Exception', 'schema', 'String', 'connection', 'schema', '_', 'Exception', 'value', 'connection', 'schema', 'value', '_', 'Exception', 'commit', 'connection', 'commit', 'rollback', 'connection', 'rollback', 'isClosed', 'connection', 'isClosed', 'close', 'connection', 'close', 'autoCommit', 'Boolean', 'connection', 'autoCommit', 'value', 'connection', 'autoCommit', 'value', 'transactionIsolation', 'Int', 'connection', 'transactionIsolation', 'value', 'connection', 'transactionIsolation', 'value', 'metadata', 'lazy', 'JdbcDatabaseMetadataImpl', 'catalog', 'connection', 'metaData', 'T', 'metadata', 'body', 'ExposedDatabaseMetadata', 'T', 'T', 'metadata', 'body', 'prepareStatement', 'sql', 'String', 'returnKeys', 'Boolean', 'PreparedStatementApi', 'generated', 'returnKeys', 'PreparedStatement', 'RETURN_GENERATED_KEYS', 'PreparedStatement', 'NO_GENERATED_KEYS', 'JdbcPreparedStatementImpl', 'connection', 'prepareStatement', 'sql', 'generated', 'returnKeys', 'prepareStatement', 'sql', 'String', 'columns', 'Array', 'String', 'PreparedStatementApi', 'JdbcPreparedStatementImpl', 'connection', 'prepareStatement', 'sql', 'columns', 'executeInBatch', 'sqls', 'List', 'String', 'types', 'sqls', 'map', 'stmt', 'StatementType', 'values', 'find', 'stmt', 'startsWith', 'it', 'name', 'StatementType', 'OTHER', 'check', 'types', 'none', 'it', 'StatementType', 'SELECT', 'type', 'types', 'distinct', 'singleOrNull', 'StatementType', 'OTHER', 'prepStatement', 'Statement', 'Unit', 'type', 'emptyList', 'prepared', 'transaction', 'Transaction', 'sql', 'String', 'PreparedStatementApi', 'originalStatement', 'prepared', 'transaction', 'sql', 'substringBefore', 'batchStatement', 'connection', 'createStatement', 'apply', 'sqls', 'forEach', 'addBatch', 'it', 'PreparedStatementApi', 'originalStatement', 'closeIfPossible', 'batchStatement', 'close', 'originalStatement', 'closeIfPossible', 'executeUpdate', 'Int', 'batchStatement', 'executeBatch', 'PreparedStatementApi', 'executeInternal', 'transaction', 'Transaction', 'executeUpdate', 'prepareSQL', 'transaction', 'Transaction', 'String', 'sqls', 'joinToString', 'arguments', 'Iterable', 'Iterable', 'Pair', 'ColumnType', 'Any', 'emptyList', 'prepStatement', 'execute', 'TransactionManager', 'current', 'setSavepoint', 'name', 'String', 'ExposedSavepoint', 'JdbcSavepoint', 'name', 'connection', 'setSavepoint', 'name', 'releaseSavepoint', 'savepoint', 'ExposedSavepoint', 'connection', 'releaseSavepoint', 'savepoint', 'JdbcSavepoint', 'savepoint', 'rollback', 'savepoint', 'ExposedSavepoint', 'connection', 'rollback', 'savepoint', 'JdbcSavepoint', 'savepoint']\n"
     ]
    }
   ],
   "source": [
    "get_tokens_pygments(content, \"kotlin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "{-# LANGUAGE MultiParamTypeClasses #-}\n",
    "module Math.Grads.Algo.Isomorphism.Types\n",
    "  ( VertexIndex\n",
    "  , VComparator\n",
    "  , EComparator\n",
    "  , GComparable(..)\n",
    "  ) where\n",
    "\n",
    "import           Math.Grads.Graph (Graph, GraphEdge)\n",
    "\n",
    "\n",
    "-- | Type alias for 'Int'.\n",
    "--\n",
    "type VertexIndex = Int\n",
    "\n",
    "-- | Function that checks whether two vertices are identical.\n",
    "-- Due to properties related to index of vertex,\n",
    "-- like number of neighbors, we consider vertex indices instead of vertices.\n",
    "--\n",
    "type VComparator v1 v2 = VertexIndex -> VertexIndex -> Bool\n",
    "\n",
    "-- | Function that checks whether two edges are identical.\n",
    "-- Due to properties related to index of vertex,\n",
    "-- like belonging to a cycle, we consider GraphEdge (Int, Int, e) instead of e.\n",
    "--\n",
    "type EComparator e1 e2 = GraphEdge e1 -> GraphEdge e2 -> Bool\n",
    "\n",
    "-- | Type class for graphs that could be checked for isomorphism.\n",
    "--\n",
    "class (Graph g1, Graph g2) => GComparable g1 v1 e1 g2 v2 e2 where\n",
    "  vComparator :: g1 v1 e1 -> g2 v2 e2 -> VComparator v1 v2\n",
    "  eComparator :: g1 v1 e1 -> g2 v2 e2 -> EComparator e1 e2\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Token.Name, Token.Name.Namespace}\n",
      "['Math.Grads.Algo.Isomorphism.Types', 'Math.Grads.Graph', 'v1', 'v2', 'e1', 'e2', 'e1', 'e2', 'g1', 'g2', 'g1', 'v1', 'e1', 'g2', 'v2', 'e2', 'vComparator', 'g1', 'v1', 'e1', 'g2', 'v2', 'e2', 'v1', 'v2', 'eComparator', 'g1', 'v1', 'e1', 'g2', 'v2', 'e2', 'e1', 'e2']\n"
     ]
    }
   ],
   "source": [
    "get_tokens_pygments(content, \"haskell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
